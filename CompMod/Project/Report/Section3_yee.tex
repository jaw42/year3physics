%!TEX root = main.tex

\section{Yee's Algorithm} % (fold)
\label{sec:yee_s_algorithm}
Yee's algorithm is a method for solving coupled differential equations, specifically Maxwell's laws, computationally by taking an approximation to the differential as the central differences method.

\subsection{Central Differences Method} % (fold)
\label{sub:central_differences_method}
We shall first look at the approximation to the differential that will be used, the central differences method. 

Consider the Taylor expansion for the function $f(x)$ about the point $x_0\pm\frac{\delta}{2}$,
\begin{align}
	f\left(x_0 + \frac{\delta}{2}\right) &= f(x_0) + \frac{\delta}{2}f'(x_0) + \frac{1}{2!}\left(\frac{\delta}{2}\right)^2f''(x_0) + \frac{1}{3!}\left(\frac{\delta}{2}\right)^3f'''(x_0) + \ldots \\
	f\left(x_0 - \frac{\delta}{2}\right) &= f(x_0) - \frac{\delta}{2}f'(x_0) + \frac{1}{2!}\left(\frac{\delta}{2}\right)^2f''(x_0) - \frac{1}{3!}\left(\frac{\delta}{2}\right)^3f'''(x_0) + \ldots
\end{align}
If we subtract the second from the first, we are left with
\begin{align}
	f\left(x_0 + \frac{\delta}{2}\right) - f\left(x_0 - \frac{\delta}{2}\right) &= \delta f'(x_0) + \frac{2}{3!}\left(\frac{\delta}{2}\right)^3f'''(x_0) + \ldots
\end{align}
This can be rearranged in terms of the derivative, $f'(x_0)$,
\begin{align}
	f'(x_0) = \left.\dx{f(x)}{x}\right|_{x=x_0} &= \frac{f\left(x_0 + \frac{\delta}{2}\right) - f\left(x_0 - \frac{\delta}{2}\right)}{\delta} + O(\delta^2) 
	\intertext{We can approximate this by ignoring the higher order terms, $O(h^2)$,}
	\left.\dx{f(x)}{x}\right|_{x=x_0} &\approx \frac{f\left(x_0 + \frac{\delta}{2}\right) - f\left(x_0 - \frac{\delta}{2}\right)}{\delta} 
\end{align}
This gives us an equation with which we can approximate the gradient at a position by taking the values of the function either side of the point of interest.

There exists three different methods used for finite difference approximations. These are the forward, backward and central differences. We shall use only the central differences method since the other two have inherent issues in some situations if the function to be approximated is not well behaved. The forward approximation method is used for algorithms such as Euler's and the Runge-Kutta methods since these provide the derivative of the function at a future point whereas the backward approximation used the value from a previous iteration when future data is not yet available. The central differences method, since it uses an average of these two is used when the step separation is constant and provides much more accurate approximations, to the order of $O(h^2)$ as opposed to $O(h)$ for the other two methods. 
% subsection central_differences_method (end)

\subsection{Yee's Algorithm} % (fold)
\label{sub:yee_s_algorithm}
The algorithm used to perform finite difference time domain calculations was written by Kane Yee in 1966. It includes several steps:
\begin{enumerate}
	\item Replace all of the derivatives in Ampere's and Faraday's Laws with finite differences and discretise both space and time so that the electric and magnetic fields are staggered spatially and temporally.
	\item Solve these difference equations to obtain a set of ``update equations'' that express the future fields in terms of the past fields that have already been calculated.
	\item Update the magnetic fields to the time corresponding to one step forward in time so that they are known and do the same for the electric fields.
	\item Repeat these, stepping forward in time each time until the required duration has been covered.
\end{enumerate}
% subsection yee_s_algorithm (end)

\subsection{Finite Differences} % (fold)
\label{sub:finite_differences}
We can now replace the differential forms of the equation relating electric and magnetic fields spatially and temporally in equations~\ref{eq:max1z} and~\ref{eq:max2z} with the finite differences discussed in section~\ref{sub:central_differences_method}. The gives a form that relates the electric and magnetic field to the value of the fields one step in time previously. These are shown in equations~\ref{eq:updateeqs1} and~\ref{eq:updateeqs1}.
\begin{align}
	\frac{E^q_z(m + 1) - E^q_z(m)}{\delta_x} &= \mu \frac{H^{q+\frac{1}{2}}_y\left(m + \frac{1}{2}\right) - H^{q-\frac{1}{2}}_y\left(m - \frac{1}{2}\right)}{\delta_t} \label{eq:updateeqs2}
	\intertext{and}
	\frac{H^{q+\frac{1}{2}}_y\left(m + \frac{1}{2}\right) - H^{q+\frac{1}{2}}_y\left(m-\frac{1}{2}\right)}{\delta_x} &= \epsilon \frac{E^{q+1}_z\left(m\right) - E^q_z\left(m\right)}{\delta_t} \label{eq:updateeqs1}
\end{align}
where $m$ is the spacial step, or the location of the sample being taken, $\delta_x$ is a small difference in space between the points where the samples are taken and likewise, $\delta_t$ is a small step in the temporal direction. The values $m\pm\frac{1}{2}$ and $m\pm 1$ are the values just near to that location, a single step in space or time away, that are used to calculate the approximation.

These equations can be rearranged to give a pair of equations that give the value of the electric or magnetic field in terms of only previous results, so that the wave can be modelled at any point in time given that the wave is known at all points prior to that time. For the electric field, the equation is given in equation~\ref{eq:updateE}, and similarly, for the magnetic field in equation~\ref{eq:updateM}.
\begin{align}
	E^{q+1}_z(m) &= E^q_z(m) + \frac{\delta_t}{\epsilon\delta_x} \left[ H^{q+\frac{1}{2}}_y\left(m + \tfrac{1}{2}\right) - H^{q+\frac{1}{2}}_y\left(m-\tfrac{1}{2}\right) \right] \label{eq:updateE} \\
	H^{q+\frac{1}{2}}_y(m+\tfrac{1}{2}) &= H^{q-\frac{1}{2}}_y\left(m+\tfrac{1}{2}\right) + \frac{\delta_t}{\mu\delta_x} \Bigg[ E^q_z(m+1) - E^q_z(m) \Bigg] \label{eq:updateM}
\end{align}

These can now be used in a computational simulation of the electromagnetic field.

% subsection finite_differences (end)


% section yee_s_algorithm (end)
